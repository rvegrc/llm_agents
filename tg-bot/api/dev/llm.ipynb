{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking about the capital of Japan. I know Japan is a country in East Asia, but I need to make sure I'm accurate. Let me think.\n",
      "\n",
      "First, I remember that Japan's capital is Tokyo. But wait, is there any chance that the user might be referring to another place? Like, maybe a different country? No, the question is specifically about Japan. \n",
      "\n",
      "I should confirm the capital again to avoid confusion. Tokyo is definitely the capital. Also, I should mention that it's the largest city, which adds context. Let me double-check with my knowledge to ensure I'm not making a mistake here. Yes, Tokyo is correct. \n",
      "\n",
      "Now, I need to present this information clearly and concisely to the user. Make sure to state the capital and any additional details like its size if helpful. Alright, that should cover it.\n",
      "</think>\n",
      "\n",
      "The capital of Japan is **Tokyo**. It is the largest city in the world and serves as the political, economic, and cultural center of the country.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "LLM_API_SERVER_URL = os.getenv(\"LLM_API_SERVER_URL\")\n",
    "\n",
    "model = \"deepseek-r1:1.5b\"\n",
    "\n",
    "\n",
    "def llm_chat_tool(messages):\n",
    "    response = requests.post(\n",
    "        url=LLM_API_SERVER_URL,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        json={\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": 0.5,\n",
    "            \"max_tokens\": 256\n",
    "        }\n",
    "    )\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# Example usage\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the capital of Japan?\"}\n",
    "]\n",
    "\n",
    "output = llm_chat_tool(messages)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d17aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# llm = OllamaLLM(\n",
    "#     model=\"qwen3:0.6B\",\n",
    "#     base_url=\"http://localhost:21434\",  # Explicitly set the Ollama server URL  # P\n",
    "#     n_ctx=2048,           # Context window size\n",
    "#     n_gpu_layers=0,      # Number of GPU layers (set to 0 for CPU-only)\n",
    "#     temperature=0.7,      # Creativity control\n",
    "#     max_tokens=200,       # Max tokens to generate\n",
    "#     verbose=True          # Print debug info\n",
    "# )\n",
    "\n",
    "# response = llm.invoke(\"Что такое эгрегор?\")  # Example query\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11f3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
